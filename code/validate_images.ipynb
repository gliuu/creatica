{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "\n",
    "We assume that we have the following directory structure: \n",
    "/data/train/category1\n",
    "\n",
    "/data/train/category2etc\n",
    "\n",
    "/data/test/category1\n",
    "\n",
    "/data/test/category2etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data validation is important because it makes sure all the images we are using are working and can be properly preprocessed for training. We present a script for validating images with `PIL.Image`, and we make sure the images can be preprocessed using `ImageDataGenerator` as well. The `.py` version can be run directly from the command line, given a directory (either 'train' or 'test')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from send2trash import send2trash\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define paths and constants\n",
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(cwd, 'data')\n",
    "#data_path = \"/Users/victorialiu/git/creatica/code/data/\"\n",
    "batch_size = 32\n",
    "TARGET_SIZE = 299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line Argument Parser\n",
    "We want to be able to run our code from the command line (at least in the `.py` version of this notebook), so we use an argument parser to translate command line arguments. We require a subdirectory from which to validate images to see if they are broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse command line arguments\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-d', '--img-directory',\n",
    "        help='subdirectory to validate images from using PIL' +\n",
    "            'train, test',\n",
    "        required = True)\n",
    "#     parser.add_argument('-t', '--test-or-train',\n",
    "#         help='directory to validate images from using ImageDataGenerator' +\n",
    "#             'test, train',\n",
    "#         required = True)\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that we can open the image with `PIL.Image.open`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_images_PIL(img_directory = 'train'):\n",
    "    \"\"\"\n",
    "    Sends to trash jpg images that cannot be opened with PIL.Image\n",
    "    \"\"\"\n",
    "    bad_files = []\n",
    "    \n",
    "    #img_directory is the /train/ or /test/ directory\n",
    "    img_directory = os.path.join(data_path, img_directory)\n",
    "    \n",
    "    #categories_dir gives the full path of\n",
    "    #/train/category1 or /test/category1 etc\n",
    "    categories_dirs = [\n",
    "            os.path.join(img_directory, category) \n",
    "            for category in os.listdir(img_directory)\n",
    "            if os.path.isdir(os.path.join(img_directory, category))\n",
    "        ]\n",
    "    i = 0\n",
    "    #go through the full path of each category\n",
    "    for category_dir in categories_dirs:\n",
    "        #go through each file of /train/category1 or /test/category1 etc\n",
    "        for filename in os.listdir(category_dir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                try:\n",
    "                    Image.open(\n",
    "                        os.path.join(category_dir, filename)\n",
    "                        )\n",
    "                except:\n",
    "                    bad_files.append(\n",
    "                        os.path.join(category_dir, filename)\n",
    "                        )\n",
    "                    send2trash(os.path.join(category_dir, filename))\n",
    "    print(f'bad files according to PIL: {bad_files}')\n",
    "    print('removed all bad files to trash')\n",
    "    return bad_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Pre-processing with InceptionV3 net\n",
    "Even though we've validated our images with `PIL.Image`, we would like to validate it with the actual package we are augmenting our images with, `ImageDataGenerator`. Here, we will validate those images. Rather than automatically removing images to the trash, we return a list of incorrect files that we will manually delete. The description of `image_data_augment` and `get_images` is given below, and the actual validation code is given in the code cell block afterwards.\n",
    "\n",
    "Next, we do data augmentation in order to \"create\" more data to train from. Data augmentation includes shifting the image in small ways such that the same image can be trained from multiple perspective (i.e. a rotated image of a hot dog is still a hot dog, and now we'll have more training data). We also make sure to normalize the image by dividing by the maximum pixel value of $255$. We also write a helper function to easily call based on whether we are using testing or training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_data_augment(rescale=1/255, shear_range = False, zoom_range = False, horizontal_flip = False):\n",
    "    \"\"\"\n",
    "    declare ImageDataGenerator class for augmenting images using shear, zoom, and flips\n",
    "    normalize with 1./255\n",
    "    \"\"\"\n",
    "    return (ImageDataGenerator(\n",
    "            rescale=rescale,\n",
    "            shear_range=shear_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip))\n",
    "\n",
    "def get_images(train_or_test):\n",
    "    if train_or_test == 'train':\n",
    "        datagen = image_data_augment(shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "    else:\n",
    "        datagen = image_data_augment()\n",
    "        \n",
    "    generator = datagen.flow_from_directory(\n",
    "        os.path.join(data_path, train_or_test),\n",
    "        target_size=(TARGET_SIZE, TARGET_SIZE),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have done manual data validation through eyeballing broken images, sometimes human error happens when we are looking through thousands of images! After hours of debugging despair, we decided it's much easier to have the computer debug broken images for us. Here is a function that will tell us all the file names of the broken images. This code is a little clunky, since we are doing it after we've already made the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_invalid_images(gen):\n",
    "    \"\"\"\n",
    "    data validation\n",
    "    \"\"\"\n",
    "    incorrect_files = []\n",
    "    for i in range(len(gen)):\n",
    "        try:\n",
    "            a = gen[i]\n",
    "        except:\n",
    "            incorrect_files.append(gen.filenames[i])\n",
    "            print(f'bad index at: {i}')\n",
    "            print(f'bad filename DataImageGenerator: {gen.filenames[i]}')\n",
    "            print('need to manually remove')\n",
    "                        \n",
    "\n",
    "\n",
    "    return incorrect_files\n",
    "# gen = get_images('train')\n",
    "# determine_invalid_images(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main command line function\n",
    "\n",
    "Unfortunately, we've already run this code (a few times!), so there are no longer any more broken images, but we can assure you that it saved us countless hours of going through thousands of images searching for one broken image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/victorialiu/git/creatica/code/data/test/nothotdog', '/Users/victorialiu/git/creatica/code/data/test/hotdog', '/Users/victorialiu/git/creatica/code/data/test/cucumbers']\n",
      "Found 311 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "# comment this out when running from command line!\n",
    "    img_directory = 'test'\n",
    "    \n",
    "# #     comment out when not running from cmdline\n",
    "# #     get cmdline args\n",
    "#     args = parse_args()\n",
    "#     img_directory = args.img_directory\n",
    "\n",
    "\n",
    "    # validate images with PIL\n",
    "    validate_images_PIL(img_directory = img_directory)   \n",
    "    \n",
    "    #validate images of ImageDataGenerator\n",
    "    gen = get_images(img_directory)\n",
    "    determine_invalid_images(gen)\n",
    "    \n",
    "    return True\n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**: Victoria Liu and Gloria Liu\n",
    "\n",
    "**Last modified**: November 2020\n",
    "\n",
    "**Description**: A script to remove broken images and return a list of images incompatible with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook validate_images.ipynb to html\n",
      "[NbConvertApp] Writing 593365 bytes to validate_images.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html validate_images.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
